"""
å®æ—¶é¢„è­¦é¡µé¢
"""
import streamlit as st
from datetime import datetime, time as dt_time
from typing import Dict, List

from stock_analysis.data.providers.akshare_provider import AkShareProvider
from stock_analysis.analysis.flows import FlowAnalyzer
from stock_analysis.data.stock_list import get_stock_provider

try:
    from streamlit_autorefresh import st_autorefresh
except Exception:  # pragma: no cover - optional dependency
    st_autorefresh = None


def show_alert_page():
    st.header("ğŸ”” å®æ—¶é¢„è­¦")
    st.caption("åŸºäºèµ„é‡‘æµå‘ä¸å¤§å•é˜ˆå€¼çš„ç®€æ˜“é¢„è­¦ï¼ˆäº¤æ˜“æ—¶æ®µå†…æœ‰æ•ˆï¼‰")

    if st_autorefresh is None:
        st.warning("ç¼ºå°‘ä¾èµ– `streamlit-autorefresh`ï¼Œè¯·å…ˆåœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ã€‚")
        st.code("pip install streamlit-autorefresh", language="bash")
        return

    if "alert_codes" not in st.session_state:
        st.session_state.alert_codes = "300661,600519"

    col_a, col_b = st.columns([3, 2])
    with col_a:
        codes_input = st.text_input("ç›‘æ§åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰", value=st.session_state.alert_codes)
        st.session_state.alert_codes = codes_input
    with col_b:
        auto_refresh = st.toggle("è‡ªåŠ¨åˆ·æ–°", value=False)

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        interval_sec = st.slider("åˆ·æ–°é—´éš”(ç§’)", 5, 300, 30)
    with col2:
        net_threshold = st.number_input("å‡€æµå…¥é˜ˆå€¼(ä¸‡å…ƒ)", min_value=0.0, value=1000.0, step=100.0)
    with col3:
        large_order_threshold = st.number_input("å¤§å•é˜ˆå€¼(ä¸‡å…ƒ)", min_value=10.0, value=200.0, step=10.0)
    with col4:
        consecutive_required = st.slider("è¿ç»­è§¦å‘æ¬¡æ•°", 1, 5, 2)

    col_c1, col_c2 = st.columns(2)
    with col_c1:
        use_net = st.checkbox("å¯ç”¨å‡€æµå…¥é˜ˆå€¼", value=True)
    with col_c2:
        use_large = st.checkbox("å¯ç”¨å¤§å•é˜ˆå€¼", value=True)

    if not use_net and not use_large:
        st.warning("è¯·è‡³å°‘å¯ç”¨ä¸€ä¸ªé¢„è­¦æ¡ä»¶ã€‚")
        return

    codes = _parse_codes(codes_input)
    if not codes:
        st.info("è¯·è¾“å…¥è‡³å°‘ä¸€åªè‚¡ç¥¨ä»£ç ã€‚")
        return

    max_codes = 6
    if len(codes) > max_codes:
        st.warning(f"ç›‘æ§æ•°é‡è¿‡å¤šï¼Œå°†åªå–å‰ {max_codes} åªä»¥é¿å…è¯·æ±‚è¿‡æ…¢ã€‚")
        codes = codes[:max_codes]

    if interval_sec < 15 and len(codes) > 3:
        st.warning("åˆ·æ–°è¿‡å¿«ä¸”ç›‘æ§æ•°é‡è¾ƒå¤šï¼Œå¯èƒ½å¯¼è‡´æ•°æ®æºé™æµæˆ–å¤±è´¥ã€‚")

    is_trading, session_label = _get_trading_status(datetime.now())
    st.caption(f"äº¤æ˜“æ—¶æ®µ: {session_label}")

    if auto_refresh:
        if is_trading:
            st_autorefresh(interval=interval_sec * 1000, key="alert_refresh")
        else:
            st.warning("å½“å‰éäº¤æ˜“æ—¶æ®µï¼Œå·²è‡ªåŠ¨æš‚åœåˆ·æ–°ã€‚")
            if st.button("æ‰‹åŠ¨åˆ·æ–°"):
                st.rerun()

    provider = AkShareProvider()
    flow_analyzer = FlowAnalyzer(large_order_threshold=large_order_threshold * 10000)
    name_cache = _get_name_cache()
    streaks = st.session_state.setdefault("alert_streaks", {})

    progress = st.progress(0, text="æ­£åœ¨æ‹‰å–æ•°æ®...")
    results = []
    details: Dict[str, Dict] = {}

    for idx, code in enumerate(codes, start=1):
        df = provider.get_realtime_data(code)
        name = _get_stock_name(code, name_cache)
        if df.empty:
            results.append({
                "ä»£ç ": code,
                "åç§°": name,
                "çŠ¶æ€": "æ— æ•°æ®",
                "è¿ç»­è§¦å‘": "0",
                "æ€»å‡€æµå…¥(äº¿)": "--",
                "å¤§å•æ•°": "--",
            })
            progress.progress(int(idx / len(codes) * 100), text=f"å®Œæˆ {idx}/{len(codes)}")
            continue

        flow_summary = flow_analyzer.calculate_flows(df)
        net_inflow = flow_summary.get("large_order_net_inflow", 0) + flow_summary.get("retail_net_inflow", 0)
        large_count = int(flow_summary.get("large_order_count", 0))

        trigger_reasons = []
        if use_net and net_inflow >= net_threshold * 10000:
            trigger_reasons.append(f"å‡€æµå…¥ {net_inflow/1e8:.2f}äº¿")
        if use_large and large_count > 0:
            trigger_reasons.append(f"å¤§å• {large_count} ç¬”")

        triggered = len(trigger_reasons) > 0
        prev_streak = streaks.get(code, 0)
        streaks[code] = prev_streak + 1 if triggered else 0

        if triggered:
            if streaks[code] >= consecutive_required:
                status = "è§¦å‘"
            else:
                status = f"è§‚å¯Ÿä¸­({streaks[code]}/{consecutive_required})"
        else:
            status = "æœªè§¦å‘"

        results.append({
            "ä»£ç ": code,
            "åç§°": name,
            "çŠ¶æ€": status,
            "è¿ç»­è§¦å‘": f"{streaks[code]}/{consecutive_required}",
            "æ€»å‡€æµå…¥(äº¿)": f"{net_inflow/1e8:.2f}",
            "å¤§å•æ•°": f"{large_count}",
        })

        details[code] = {
            "df": df,
            "flow_summary": flow_summary,
            "net_inflow": net_inflow,
            "trigger_reasons": trigger_reasons,
        }

        progress.progress(int(idx / len(codes) * 100), text=f"å®Œæˆ {idx}/{len(codes)}")

    progress.empty()

    st.markdown("---")
    st.subheader("ğŸ“Œ é¢„è­¦ç»“æœ")
    updated_time = datetime.now().strftime("%H:%M:%S")
    st.caption(f"æ›´æ–°æ—¶é—´: {updated_time}")

    st.dataframe(
        results,
        use_container_width=True,
        height=260
    )

    detail_code = st.selectbox("æŸ¥çœ‹è¯¦æƒ…", [r["ä»£ç "] for r in results])
    detail = details.get(detail_code)
    if detail:
        flow_summary = detail["flow_summary"]
        net_inflow = detail["net_inflow"]
        trigger_reasons = detail["trigger_reasons"]

        if trigger_reasons:
            st.success(" | ".join(trigger_reasons))
        else:
            st.info("æœªè§¦å‘é¢„è­¦æ¡ä»¶")

        col_s1, col_s2, col_s3 = st.columns(3)
        with col_s1:
            st.metric("ä¸»åŠ›å‡€æµå…¥", f"Â¥{flow_summary.get('large_order_net_inflow', 0)/1e8:.2f}äº¿")
        with col_s2:
            st.metric("æ•£æˆ·å‡€æµå…¥", f"Â¥{flow_summary.get('retail_net_inflow', 0)/1e8:.2f}äº¿")
        with col_s3:
            st.metric("å¤§å•æ•°é‡", f"{flow_summary.get('large_order_count', 0)}")

    st.caption("æç¤ºï¼šå…è´¹æ•°æ®æºå»ºè®®åˆ·æ–°é—´éš”â‰¥30ç§’ï¼Œç›‘æ§æ•°é‡â‰¤5ã€‚")


def _get_trading_status(now: datetime) -> tuple[bool, str]:
    if now.weekday() >= 5:
        return False, "ä¼‘å¸‚"

    t = now.time()
    morning_start = dt_time(9, 30)
    morning_end = dt_time(11, 30)
    afternoon_start = dt_time(13, 0)
    afternoon_end = dt_time(15, 0)

    if morning_start <= t <= morning_end:
        return True, "ä¸Šåˆç›˜ 09:30-11:30"
    if afternoon_start <= t <= afternoon_end:
        return True, "ä¸‹åˆç›˜ 13:00-15:00"
    return False, "éäº¤æ˜“æ—¶æ®µ"


def _parse_codes(raw: str) -> List[str]:
    items = [c.strip() for c in raw.split(",")]
    items = [c for c in items if c]
    unique = []
    for code in items:
        if code not in unique:
            unique.append(code)
    return unique


def _get_name_cache() -> Dict[str, str]:
    if "alert_name_cache" not in st.session_state:
        st.session_state.alert_name_cache = {}
    return st.session_state.alert_name_cache


def _get_stock_name(code: str, cache: Dict[str, str]) -> str:
    if code in cache:
        return cache[code]
    provider = get_stock_provider()
    name = code
    try:
        res = provider.search(code, limit=1)
        if not res.empty:
            name = res.iloc[0]["åç§°"]
    except Exception:
        pass
    cache[code] = name
    return name
